---
lab:
    title: 'Build classical Machine Learning'
---
## Module 15: Build classical machine learning models with supervised learning

In this exercise, youâ€™ll dive into the realm of classical machine learning models with supervised learning. Through hands-on experimentation, you'll explore various concepts and techniques essential for building robust predictive models.

### Exercise Overview

In this module, you will:

- Explore how cost functions affect the learning process.
- Discover how models are optimized by gradient descent.
- Experiment with learning rates, and see how they can affect training.

These exercises are designed to provide you with practical insights into the fundamental principles of supervised learning, allowing you to experiment and gain a deeper understanding of the learning process.

### Jupyter Notebooks

To get started, access the following Jupyter notebooks:

1. [Implement Supervised Learning](../notebook/15/1-exercise-separate-data-test-model.ipynb) - Explore supervised learning in Python.
2. [Optimize a Model by using Cost Functions](../notebook/15/2-exercise-optimize-models.ipynb) - Dive into different cost functions and their impact on model training.
3. [Implement Gradient Descent](../notebook/15/3-exercise-implement-gradient-descent.ipynb) -  Explore gradient descent optimization with different learning rates and observe their effects on model training.

These notebooks will guide you through interactive exercises where you can manipulate parameters, visualize results, and gain hands-on experience with classical machine learning techniques.

Happy experimenting!
